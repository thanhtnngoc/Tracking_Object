# import cv2

# # M·ªü camera USB (th∆∞·ªùng l√† /dev/video0)
# cap = cv2.VideoCapture(0)  # 0 = camera ƒë·∫ßu ti√™n, ƒë·ªïi th√†nh 1 n·∫øu b·∫°n c√≥ nhi·ªÅu camera

# if not cap.isOpened():
#     print("‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c camera!")
#     exit()

# while True:
#     ret, frame = cap.read()
#     if not ret:
#         print("‚ùå Kh√¥ng nh·∫≠n ƒë∆∞·ª£c khung h√¨nh!")
#         break

#     # Hi·ªÉn th·ªã h√¨nh ·∫£nh
#     cv2.imshow("USB Camera", frame)

#     # Nh·∫•n ESC ƒë·ªÉ tho√°t
#     key = cv2.waitKey(1)
#     if key == 27:  # 27 l√† m√£ ASCII c·ªßa ph√≠m ESC
#         break

# # Gi·∫£i ph√≥ng t√†i nguy√™n
# cap.release()
# cv2.destroyAllWindows()


import cv2
from ultralytics import YOLO
import math

# === 1. Load model YOLOv8 pretrained (COCO c√≥ class "person") ===
model = YOLO("yolov8n.pt")  # b·∫°n c√≥ th·ªÉ ƒë·ªïi sang yolov8s.pt, yolov8m.pt, v.v.

# === 2. M·ªü camera USB ===
cap = cv2.VideoCapture(0)  # 0: camera ƒë·∫ßu ti√™n (/dev/video0)
if not cap.isOpened():
    print("‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c camera!")
    exit()

print("‚úÖ Camera ƒëang ch·∫°y... Nh·∫•n ESC ƒë·ªÉ tho√°t.")

# === 3. V√≤ng l·∫∑p ƒë·ªçc khung h√¨nh & detect ng∆∞·ªùi ===
while True:
    ret, frame = cap.read()
    if not ret:
        print("‚ùå Kh√¥ng nh·∫≠n ƒë∆∞·ª£c khung h√¨nh!")
        break

    h, w, _ = frame.shape
    cx_frame = w // 2
    cy_frame = h // 2

    # === 4. D√≤ ng∆∞·ªùi trong khung h√¨nh ===
    results = model.predict(source=frame, classes=[0], conf=0.5, verbose=False)

    # === 5. Hi·ªÉn th·ªã k·∫øt qu·∫£ l√™n khung h√¨nh ===
    annotated_frame = results[0].plot()  # V·∫Ω bounding boxes

    cv2.circle(annotated_frame, (cx_frame, cy_frame), 6, (255, 0, 0), -1)

    MIN_AREA = 5000
    boxes = results[0].boxes.xyxy
    for box in boxes:
        
        x1, y1, x2, y2 = map(int, box[:4])  
        cx = int((x1 + x2) / 2)
        cy = int((y1 + y2) / 2)
        width = x2 - x1
        height = y2 - y1
        area = width*height

        if area < MIN_AREA:
            continue

        # V·∫Ω t√¢m ng∆∞·ªùi (m√†u ƒë·ªè)
        cv2.circle(annotated_frame, (cx, cy), 6, (0, 0, 255), -1)

        # V·∫Ω ƒë∆∞·ªùng n·ªëi
        cv2.line(annotated_frame, (cx_frame, cy_frame), (cx, cy), (0, 255, 255), 2)

        # === 7. T√≠nh kho·∫£ng c√°ch t·ª´ t√¢m ·∫£nh ƒë·∫øn t√¢m ng∆∞·ªùi ===
        dx = cx - cx_frame
        dy = cy - cy_frame
        distance = math.sqrt(dx**2 + dy**2)

        # Hi·ªÉn th·ªã th√¥ng tin
        cv2.putText(annotated_frame, f"dx={dx}, dy={dy}", (cx + 10, cy - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
        cv2.putText(annotated_frame, f"dist={int(distance)} px", (cx + 10, cy + 15),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

    cv2.imshow("YOLOv8 Person Detection", annotated_frame)

    # Nh·∫•n ESC ƒë·ªÉ tho√°t
    if cv2.waitKey(1) == 27:
        break

# === 6. Gi·∫£i ph√≥ng t√†i nguy√™n ===
cap.release()
cv2.destroyAllWindows()
print("üõë ƒê√£ d·ª´ng camera.")
